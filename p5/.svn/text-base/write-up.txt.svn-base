This is the write-up for assignment # 5

1. The latency and throughput of our linked list compared with those of the
lists in project4 are shown in the following tables.

We test with Read ratio R=34, the key range m=256, and the number of threads p=4:

lock	#thread ops		latency		throughput

basic	
	4	100		716715		139525
	4	1000		5382712		185779
	4	10000		42815624	233559
	4	100000		247749809	403633
	4	1000000		3550329276	281664

shared	
	4	100		1394514		71709
	4	1000		10511803	95131
	4	10000		99879234	100120
	4	100000		968601238	103241
	4	1000000		9327271740	107212

spin
	4	100		405666		246508
	4	1000		2972635		336401
	4	10000		42161397	237183
	4	100000		273765928	365275
	4	1000000		3227565052	309831

tas-eb
	4	100		385829		259182
	4	1000		1761752		567616
	4	10000		21970223	455161
	4	100000		180680321	553463
	4	1000000		1350994599	740195

hand-over	
	4	100		132386460	755
	4	1000		412423891	2424
	4	10000		17234085556	580
	4	100000		198669505849 	503
	4	1000000		2218487439114 	450

lazy
	4	100		378368		264292
	4	1000		1964713		508980
	4	10000		24849450	402423
	4	100000		386223834	258917
	4	1000000		5062811021	197518

transaction
	4	100		4836610		20675
	4	1000		9956496		100436
	4	10000		139488468	71690
	4	100000		1556617924	64241
	4	1000000		15345932054	65163

From this data, we can see that except hand-over-hand,  all other
lock-based versions of linked list did better than its transaction version.
The latency of transaction version is longer and the throughput is worse than
the other kinds of locks.
I think the reason for this would be that all operations(lookup, insert,
remove) should read O(n) nodes in the lists. Therefore, any
insertion or deletion of a node would cause transactions to abort. These too
many aborts cannot make transactions faster than traditional lock-based code
in most cases. In hand-over linked list, a insert or delete operation cannot 
finish until its previous insert/delete operations release the lock of the
each node on the traverse process. This constrains causes it much slower than
other locked based code and transactional linked list.
Transaction is more optimistic than locks. The former tries to suppose no
conflics exists at the beginning and try to deal with problems with conflicts
occur. Therefore, it is not surprising to see when number of threads are
getting larger, conflicts that need to deal with in transaction increases, and
the performance becomes worse. Locks tend to avoid conflicts in advance, which
remains a relatively good performance in multithreaded systems.

2. Here below shows the throughput and latency of our blanced tree with
various number of threads, and different lookup percentage
	R	p	m	ops		time		throughput
 	0  	1  	16  	1791672  	1000008073  	1791657
 	0  	2  	16  	201308  	1000008437  	201306
 	0  	4  	16  	219351  	1000027400  	219344
 	0  	6  	16  	218578  	1000059053  	218565
 	0  	8  	16  	225430  	1001420784  	225110
 	0  	10  	16  	220726  	1000512331  	220612
 	0  	1  	64  	1748018  	1000009806  	1748000
 	0  	2  	64  	237296  	1000013012  	237292
 	0  	4  	64  	214448  	1000037909  	214439
 	0  	6  	64  	219476  	1000053476  	219464
 	0  	8  	64  	236401  	1001524473  	236041
 	0  	10  	64  	232076  	1000121756  	232047
 	0  	1  	256  	1644868  	1000009855  	1644851
 	0  	2  	256  	177879  	1000012588  	177876
 	0  	4  	256  	219645  	1000045671  	219634
 	0  	6  	256  	217774  	1000052220  	217762
 	0  	8  	256  	219102  	1000061964  	219088
 	0  	10  	256  	222147  	1007404386  	220514
 	33  	1  	16  	2428888  	1000006900  	2428871
 	33  	2  	16  	386006  	1000012384  	386001
 	33  	4  	16  	304827  	1000023395  	304819
 	33  	6  	16  	332849  	1000035296  	332837
 	33  	8  	16  	317876  	1000044342  	317861
 	33  	10  	16  	309320  	1000090855  	309291
 	33  	1  	64  	2315076  	1000006531  	2315060
 	33  	2  	64  	320017  	1000010650  	320013
 	33  	4  	64  	292508  	1000043218  	292495
 	33  	6  	64  	303496  	1000023235  	303488
 	33  	8  	64  	293659  	1000092214  	293631
 	33  	10  	64  	284995  	1000091873  	284968
 	33  	1  	256  	2162120  	1000007189  	2162104
 	33  	2  	256  	309773  	1000017205  	309767
 	33  	4  	256  	266335  	1000028812  	266327
 	33  	6  	256  	286311  	1000038692  	286299
 	33  	8  	256  	280776  	1000038663  	280765
 	33  	10  	256  	269652  	1000055941  	269636
 	100  	1  	16  	10684231  	1000066337  	10683522
 	100  	2  	16  	8817818  	1000004966  	8817774
 	100  	4  	16  	13328327  	1000002987  	13328287
 	100  	6  	16  	15948866  	1000002687  	15948823
 	100  	8  	16  	18276820  	1000004046  	18276746
 	100  	10  	16  	17891442  	1000003512  	17891379
 	100  	1  	64  	10563710  	1000002934  	10563679
 	100  	2  	64  	6939918  	1000003001  	6939897
 	100  	4  	64  	11037541  	1000005191  	11037483
 	100  	6  	64  	12590722  	1000004270  	12590668
 	100  	8  	64  	15295631  	1000004032  	15295569
 	100  	10  	64  	15564571  	1000004687  	15564498
 	100  	1  	256  	10080907  	1000002921  	10080877
 	100  	2  	256  	5423260  	1000003275  	5423242
 	100  	4  	256  	8546048  	1000004165  	8546012
 	100  	6  	256  	10061721  	1000003601  	10061684
 	100  	8  	256  	10689438  	1000004038  	10689394
 	100  	10  	256  	10415289  	1005124159  	10362191

From the data shown above, we can see that our balanced tree has scalability.
As the number of threads grows, the latency does not grow. Neither does
throughput decreases with the increase of number of threads. Notice that there
is an obvious decrease in performance from one thread to two threads. Because
the multithread mode starts with two threads. When the thread number is larger
than two nodes, even though the contention among threads becomes much
severe than when there are fewer threads, the parallelism of task sharing among different
threads helps to improve scalability. I went over through the GCC TM
implementation. I found that GCC TM does not handle retry effectively: there
are no mechanisms like exponential back-off to avoid excessive contention and
overwhelming amount of aborts. Which seems to be a bottleneck in performance
improvement. 

3. we select read/write ratio R from this set: {0, 33, 100} and select key
ranges m from this set: {16, 64, 256}. we test the number of threads p from
this set {2, 4, 8}. We test random 1000000 operations as our workload.

The throughput and latency of our simple hash table compared with linked list
and balance tree are shown in the following tables.

Linklist:	                      BST:		                    Hash:
 R   p   m    ops       time         thro    ops       time         thro   ops	      time	   thro
 0   1   16   9169458   1000003227   9169428 1791672   1000008073   1791657 9546219   1000002787   9546192
  0   2   16   2725608   1000003247   2725599 201308   1000008437   201306 4380073   1000004353   4380053
  0   4   16   2989358   1000008785   2989331 219351   1000027400   219344 5597622   1000005228   5597592
  0   6   16   3101776   1000005564   3101758 218578   1000059053   218565 6646568   1001479063   6636751
  0   8   16   2002880   1000009692   2002860 225430   1001420784   225110 5642137   1000006088   5642102
  0   10   16   1100846   1012363332   1087402 220726   1000512331   220612 3204126   1000063658   3203922
  0   1   64   7730058   1000003641   7730029 1748018   1000009806   1748000 9545356   1000003857   9545319
  0   2   64   1627102   1000003068   1627097 237296   1000013012   237292 4528152   1000003007   4528138
  0   4   64   1751333   1000006807   1751321 214448   1000037909   214439 5903419   1000004844   5903390
  0   6   64   1425191   1000007158   1425180 219476   1000053476   219464 7364030   1000004751   7363995
  0   8   64   694037   1004660586   690817 236401   1001524473   236041 7765568   1000004527   7765532
  0   10   64   515824   1011244679   510088 232076   1000121756   232047 3583394   1008250281   3554071
  0   1   256   4810444   1000006806   4810411 1644868   1000009855   1644851 9675793   1000003217   9675761
  0   2   256   656621   1000009657   656614 177879   1000012588   177876 4722608   1000003279   4722592
  0   4   256   694560   1000005766   694555 219645   1000045671   219634 6289601   1000008331   6289548
  0   6   256   572754   1000015867   572744 217774   1000052220   217762 7651129   1000004378   7651095
  0   8   256   241398   1014205771   238016 219102   1000061964   219088 7894654   1000004788   7894616
  0   10   256   166390   1006477649   165319 222147   1007404386   220514 3145426   1015613088   3097071
  33   1   16   9221825   1000002497   9221801 2428888   1000006900   2428871 9683030   1000003388   9682997
  33   2   16   3506043   1000003329   3506031 386006   1000012384   386001 5716083   1000004558   5716056
  33   4   16   4157812   1000003485   4157797 304827   1000023395   304819 7393170   1000004021   7393140
  33   6   16   3972161   1000007967   3972129 332849   1000035296   332837 9163825   1000007706   9163754
  33   8   16   3009235   1001051638   3006073 317876   1000044342   317861 8162984   1000005918   8162935
  33   10   16   1640704   1002089935   1637282 309320   1000090855   309291 4337622   1000020653   4337532
  33   1   64   7731547   1000003112   7731522 2315076   1000006531   2315060 9724796   1000004530   9724751
  33   2   64   2112143   1000004185   2112134 320017   1000010650   320013 5910857   1000004058   5910833
  33   4   64   2337062   1000004712   2337050 292508   1000043218   292495 7803245   1000004421   7803210
  33   6   64   2266570   1000005368   2266557 303496   1000023235   303488 9647921   1000003584   9647886
  33   8   64   1200106   1000721932   1199240 293659   1000092214   293631 6064290   1003089192   6045613
  33   10   64   772974   1015397134   761252 284995   1000091873   284968 4385612   1014455207   4323120
  33   1   256   4853791   1000006774   4853758 2162120   1000007189   2162104 9723407   1000003559   9723372
  33   2   256   819783   1000004798   819779 309773   1000017205   309767 6126139   1000002899   6126121
  33   4   256   953110   1000005239   953105 266335   1000028812   266327 8161859   1000003717   8161828
  33   6   256   939440   1000013263   939427 286311   1000038692   286299 10101438   1000019358   10101242
  33   8   256   428223   1008233522   424726 280776   1000038663   280765 7465072   1001361150   7454924
  33   10   256   305053   1008108495   302599 269652   1000055941   269636 5239614   1001028568   5234230
  100   1   16   10944661   1000003637   10944621 10684231   1000066337   10683522 11824257   1000003644   11824213
  100   2   16   7627042   1000003043   7627018 8817818   1000004966   8817774 18006202   1000002836   18006150
  100   4   16   12558094   1000004633   12558035 13328327   1000002987   13328287 27914371   1000005355   27914221
  100   6   16   14462809   1000007968   14462693 15948866   1000002687   15948823 30907137   1000637610   30887442
  100   8   16   16095404   1000003874   16095341 18276820   1000004046   18276746 36908899   1000005416   36908699
  100   10   16   16610038   1000003576   16609978 17891442   1000003512   17891379 37769615   1000503448   37750609
  100   1   64   8534811   1000003154   8534784 10563710   1000002934   10563679 11380100   1000002451   11380072
  100   2   64   3617535   1000002726   3617525 6939918   1000003001   6939897 17881457   1000002963   17881404
  100   4   64   5359883   1000005170   5359855 11037541   1000005191   11037483 27937065   1000003443   27936968
  100   6   64   5776265   1000003747   5776243 12590722   1000004270   12590668 29358556   1000005087   29358406
  100   8   64   7233385   1000004473   7233352 15295631   1000004032   15295569 38540146   1000418378   38524028
  100   10   64   7179768   1000006905   7179718 15564571   1000004687   15564498 37676789   1010137978   37298656
  100   1   256   5213889   1000004088   5213867 10080907   1000002921   10080877 11542545   1000002970   11542510
  100   2   256   1010768   1000003582   1010764 5423260   1000003275   5423242 17093173   1000003048   17093120
  100   4   256   1808786   1000005723   1808775 8546048   1000004165   8546012 27616454   1000003948   27616344
  100   6   256   1909615   1000008410   1909598 10061721   1000003601   10061684 30615381   1000005000   30615227
  100   8   256   2189169   1000005991   2189155 10689438   1000004038   10689394 35531657   1000004206   35531507
  100   10   256   2148363   1000013540   2148333 10415289   1005124159   10362191 34818408   1000003476   34818286
From the data shown above, we can see that hash table has better performance
than binary search tree and list. Because of the hash function, the hash table makes chances of
conflicts smaller. Also because of this, the performance of hash table
improves more obviously with the increase of number of threads than the
performance improvement of list and BST. As the key ranges go up, the
performance of both linked list and simple hash table become worse because
too many different items (with too many keys) would result in longer time
to locate an item in both data structures; thus esier to be aborted by another
transaction. However, balanced tree would be O(Log(n)) complexity in terms of 
locating an item. So its performance is resistant to downgrade when key ranges
go up. This degradation is the inherent bottleneck for linked list and simple
hash table.

Another bottleneck for balanced tree is when there is a larger read/write
ratio in the workloads. In this case, the performance bottleneck of balanced tree mainly
comes from its consistently altering the tree structure to maintain balance,
which easily makes other insert/remove operations to abort. 

4. We compared the performance of both resizable hash table and the that of
the simple hash table with various r, m and p.
		Hashtable:   			Resizable:      
  R   p   m    ops       time         thro    ops       time         thro
  0   1   16   9546219   1000002787   9546192 9138761   1000002472   9138738
  0   2   16   4380073   1000004353   4380053 4067281   1000004730   4067261
  0   4   16   5597622   1000005228   5597592 4954209   1000004538   4954186
  0   6   16   6646568   1001479063   6636751 5889399   1000003960   5889375
  0   8   16   5642137   1000006088   5642102 2865231   1005563857   2849377
  0   10   16   3204126   1000063658   3203922 2742927   1008716092   2719225
  0   1   64   9545356   1000003857   9545319 8960665   999967677   8960954
  0   2   64   4528152   1000003007   4528138 4210114   1000005397   4210091
  0   4   64   5903419   1000004844   5903390 5321717   1000002485   5321703
  0   6   64   7364030   1000004751   7363995 6147857   1000005721   6147821
  0   8   64   7765568   1000004527   7765532 4463734   1000005788   4463708
  0   10   64   3583394   1008250281   3554071 2743368   1007899481   2721866
  0   1   256   9675793   1000003217   9675761 9299663   1000003488   9299630
  0   2   256   4722608   1000003279   4722592 4441066   1000005359   4441042
  0   4   256   6289601   1000008331   6289548 5632073   1000004334   5632048
  0   6   256   7651129   1000004378   7651095 6787713   1000012933   6787625
  0   8   256   7894654   1000004788   7894616 6765421   1000004052   6765393
  0   10   256   3145426   1015613088   3097071 3316665   1009489227   3285488
  33   1   16   9683030   1000003388   9682997 9451205   1000003044   9451176
  33   2   16   5716083   1000004558   5716056 5384084   1000007126   5384045
  33   4   16   7393170   1000004021   7393140 6665055   1000008501   6664998
  33   6   16   9163825   1000007706   9163754 7656416   1000005696   7656372
  33   8   16   8162984   1000005918   8162935 5775514   1000005675   5775481
  33   10   16   4337622   1000020653   4337532 3376784   1010103954   3343006
  33   1   64   9724796   1000004530   9724751 9383361   1000003058   9383332
  33   2   64   5910857   1000004058   5910833 5505854   1000003223   5505836
  33   4   64   7803245   1000004421   7803210 7112429   1000003933   7112401
  33   6   64   9647921   1000003584   9647886 8850218   1000003767   8850184
  33   8   64   6064290   1003089192   6045613 6477190   1002134589   6463393
  33   10   64   4385612   1014455207   4323120 3447811   1015421698   3395447
  33   1   256   9723407   1000003559   9723372 9171046   1000002293   9171024
  33   2   256   6126139   1000002899   6126121 5763341   1000003631   5763320
  33   4   256   8161859   1000003717   8161828 7461796   1000004187   7461764
  33   6   256   10101438   1000019358   10101242 9081317   1000007578   9081248
  33   8   256   7465072   1001361150   7454924 10154771   1000005336   10154716
  33   10   256   5239614   1001028568   5234230 3811521   1004890522   3792971
  100   1   16   11824257   1000003644   11824213 11716967   1000002721   11716935
  100   2   16   18006202   1000002836   18006150 17946749   1000002811   17946698
  100   4   16   27914371   1000005355   27914221 28028330   1000003428   28028233
  100   6   16   30907137   1000637610   30887442 32493698   1000007864   32493442
  100   8   16   36908899   1000005416   36908699 37375750   1000005614   37375540
  100   10   16   37769615   1000503448   37750609 37677530   1000239292   37668516
  100   1   64   11380100   1000002451   11380072 11693053   1000003452   11693012
  100   2   64   17881457   1000002963   17881404 17842611   1000003134   17842555
  100   4   64   27937065   1000003443   27936968 28008440   1000003651   28008337
  100   6   64   29358556   1000005087   29358406 31772182   1000003265   31772078
  100   8   64   38540146   1000418378   38524028 38440091   1000003707   38439948
  100   10   64   37676789   1010137978   37298656 37869217   1000004243   37869056
  100   1   256   11542545   1000002970   11542510 11626975   1000076753   11626082
  100   2   256   17093173   1000003048   17093120 17989898   1000002583   17989851
  100   4   256   27616454   1000003948   27616344 28130623   1000002801   28130544
  100   6   256   30615381   1000005000   30615227 32255189   1000004925   32255030
  100   8   256   35531657   1000004206   35531507 37964336   1000003823   37964190
  100   10   256   34818408   1000003476   34818286 38835041   1000015426   38834441

It looks like simple hash table over-performs the resizable hash table in most
cases, and especially when m=8192, which is much greater than the original
table size 1024. The complexity for the resizable hash table is O(1) + resize
overhead = O(n). And The complexity for the regular hash table is n/TableSize = O(n). 
Building a scalable lock-based resizable hash table would be harder because we
cannot allow one thread resize the hash table while other threads are waiting:
that would degrade scalability. Therefore, we need to assign each thread
a portion of the resizing work, which adds more complexity in building
such resizable hash table. 

We observed starvation in resize operation when we use our own hash function:
a thread tries to resize the hash table, making it larger and larger, but yet
the amount of items mapped to each bucket cannot shrink to a amount smaller
than the limit(i.e., 8 in our case). And finally we found a hash function that
can get rid of this starvation problem.


